{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the working directory\n",
    "import os\n",
    "abspath = os.path.abspath(\"./src\")\n",
    "dname = os.path.dirname(abspath)\n",
    "os.chdir(dname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Manim Community <span style=\"color: #008000; text-decoration-color: #008000\">v0.18.0.post0</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Manim Community \u001b[32mv0.\u001b[0m\u001b[32m18.0\u001b[0m\u001b[32m.post0\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from manim import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import sentencepiece as spm\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.processing import src_processing\n",
    "from src.transformer import Transformer\n",
    "\n",
    "from utils import to_tokens, animate_emb, show_emb, animate_attn, remove_invisible_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                       \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"media/jupyter/Tokenization@2024-04-27@17-19-56.mp4\" controls autoplay loop style=\"max-width: 60%;\"  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%manim -qk -v WARNING Tokenization\n",
    "\n",
    "class Tokenization(Scene):\n",
    "    def get_unique_chars(self, strs):\n",
    "        unique_chars = set()\n",
    "        for s in strs:\n",
    "            unique_chars.update(set(s))\n",
    "        return list(unique_chars)\n",
    "\n",
    "    def get_unique_words(self, strs):\n",
    "        unique_words = set()\n",
    "        for s in strs:\n",
    "            unique_words.update(s.split())\n",
    "        return list(unique_words)\n",
    "\n",
    "    def construct(self):\n",
    "        # Tokenization & Numericalization\n",
    "        df = pd.read_csv(\"../data/shk2mod.csv\", index_col=0)\n",
    "        df.drop(\"id\", axis=1, inplace=True)                                  \n",
    "        d = df.to_numpy()\n",
    "        src = d[0,0]\n",
    "        src_stn = Tex(src).scale(0.75)\n",
    "        self.play(Write(src_stn))\n",
    "        self.wait(2)\n",
    "\n",
    "        # Title\n",
    "        title = Title(\"Tokenization\")\n",
    "        self.play(Write(title), FadeOut(src_stn))\n",
    "        self.wait(1)\n",
    "\n",
    "        # Tokenizer types\n",
    "        subtitle1 = Tex(\"Character Level Tokenization\").scale(0.7).next_to(title, DOWN).to_edge(LEFT)\n",
    "        subtitle2 = Tex(\"Word Level Tokenization\").scale(0.7).next_to(title, DOWN).to_edge(RIGHT)\n",
    "        self.play(Write(subtitle1))\n",
    "        self.play(Write(subtitle2))\n",
    "        self.wait(1)\n",
    "\n",
    "        # Char Level Tokenizer\n",
    "        unq_chars = self.get_unique_chars(d[:,0])\n",
    "        unq_chars = VGroup(*[Text(s).scale(0.3) for s in unq_chars])\n",
    "        unq_chars.arrange_in_grid(rows=5, cols=20, buff=0.05).to_edge(DOWN).to_edge(LEFT).shift(0.15*RIGHT+UP)\n",
    "        char_box = SurroundingRectangle(unq_chars, buff=SMALL_BUFF, color=WHITE).scale(0.65)\n",
    "        self.play(Create(char_box))\n",
    "        self.wait(1)\n",
    "        for i in range(len(unq_chars)):\n",
    "            stn = Tex(d[i,0]).scale(0.3).next_to(subtitle1, DOWN).shift(0.25*DOWN)\n",
    "            self.play(Write(unq_chars[i]), FadeIn(stn), run_time=0.05)\n",
    "            self.play(FadeOut(stn), run_time=0.05)\n",
    "        self.wait(1)\n",
    "\n",
    "        src = d[0,0]\n",
    "        src_stn = Tex(src).scale(0.5).next_to(subtitle1, DOWN).shift(0.25*DOWN)\n",
    "        src_chars = VGroup(Tex(src[1]))\n",
    "        src_chars.add(SurroundingRectangle(src_chars[-1], buff=0.25))\n",
    "        for char in src[2:]:\n",
    "            if char != \" \":\n",
    "                src_chars.add(Tex(char).next_to(src_chars[-1], RIGHT))\n",
    "                src_chars.add(SurroundingRectangle(src_chars[-1], buff=0.25))\n",
    "        src_chars.scale(0.45).move_to(src_stn).to_edge(LEFT)\n",
    "        self.play(Write(src_stn))\n",
    "        self.wait(1)\n",
    "        self.play(ReplacementTransform(src_stn, src_chars))\n",
    "        self.wait(1)\n",
    "\n",
    "        char_drawback = Tex(\"An 8 word sentence has turned into a sequence of length 26!\").scale(0.5).next_to(src_chars, DOWN).shift(0.25*DOWN)\n",
    "        self.play(Write(char_drawback))\n",
    "        self.wait(1)\n",
    "        \n",
    "        # Word level tokenizer\n",
    "        unq_words = self.get_unique_words(d[:,0])\n",
    "        unq_words = VGroup(*[Text(s).scale(0.3) for s in unq_words[:50]])\n",
    "        unq_words.arrange_in_grid(rows=10, cols=5, buff=0.05).to_edge(DOWN).to_edge(RIGHT).shift(DOWN)\n",
    "        word_box = SurroundingRectangle(unq_words, buff=SMALL_BUFF, color=WHITE)\n",
    "        self.play(Create(word_box))\n",
    "        self.wait(1)\n",
    "        for i in range(len(unq_words[:50])):\n",
    "            stn = Tex(d[i,0]).scale(0.3).next_to(subtitle2, DOWN).shift(0.25*DOWN)\n",
    "            self.play(Write(unq_words[i]), FadeIn(stn), run_time=0.05)\n",
    "            self.play(FadeOut(stn), run_time=0.05)\n",
    "        self.wait(1)\n",
    "\n",
    "        src = d[0,0]\n",
    "        src_stn = Tex(src).scale(0.5).next_to(subtitle2, DOWN).shift(0.25*DOWN)\n",
    "        src_words = VGroup(Tex(src.split()[0]))\n",
    "        src_words.add(SurroundingRectangle(src_words[-1], buff=0.25))\n",
    "        for word in src.split()[1:]:\n",
    "            src_words.add(Tex(word).next_to(src_words[-1], RIGHT))\n",
    "            src_words.add(SurroundingRectangle(src_words[-1], buff=0.25))\n",
    "        src_words.scale(0.35).move_to(src_stn).to_edge(RIGHT)\n",
    "        self.play(Write(src_stn))\n",
    "        self.wait(1)\n",
    "        self.play(ReplacementTransform(src_stn, src_words))\n",
    "        self.wait(1)\n",
    "\n",
    "        word_drawback = Tex(\"Vocabulary size here is 73558!\").scale(0.5).next_to(src_words, DOWN).shift(0.25*DOWN)\n",
    "        self.play(Write(word_drawback))\n",
    "        self.wait(1)\n",
    "\n",
    "        # Transition\n",
    "        self.play(\n",
    "            *[FadeOut(mob)for mob in self.mobjects if mob != title]\n",
    "        )\n",
    "        \n",
    "        title_ = Title(\"Sub-Word Tokenization\")\n",
    "        self.play(ReplacementTransform(title, title_))\n",
    "        self.wait(1)\n",
    "\n",
    "        self.wait(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                      \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"media/jupyter/SentencePiece@2024-04-27@17-25-13.mp4\" controls autoplay loop style=\"max-width: 60%;\"  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%manim -qk -v WARNING SentencePiece\n",
    "\n",
    "class SentencePiece(Scene):\n",
    "    def construct(self):\n",
    "        # Transition\n",
    "        title = Title(\"Sub-Word Tokenization\")\n",
    "        self.add(title)\n",
    "        self.wait(1)\n",
    "\n",
    "        # Sub word tokenization\n",
    "        spm_sc = ImageMobject(\"../data/spm.png\")\n",
    "        self.play(FadeIn(spm_sc))\n",
    "        self.wait(1)\n",
    "        self.play(FadeOut(spm_sc))\n",
    "        self.wait(1)\n",
    "\n",
    "        df = pd.read_csv(\"../data/shk2mod.csv\", index_col=0)                           \n",
    "        df.drop(\"id\", axis=1, inplace=True)                                  \n",
    "        d = df.to_numpy()\n",
    "        src, trg = d[:,0], d[:,1]\n",
    "        sk_stns = VGroup(Tex(src[0]))\n",
    "        md_stns = VGroup(Tex(trg[0]))\n",
    "        np.random.seed(0)\n",
    "        idx = np.random.randint(1, len(src), 7)\n",
    "        for i in range(7):\n",
    "            if i != 3:\n",
    "                # Shakespeare sentence\n",
    "                sk_stn = Tex(src[idx[i]]).next_to(sk_stns[-1], DOWN).shift(0.25*DOWN)\n",
    "                sk_stns.add(sk_stn)\n",
    "                # Modern sentence\n",
    "                md_stn = Tex(trg[idx[i]]).next_to(md_stns[-1], DOWN).shift(0.25*DOWN)\n",
    "                md_stns.add(md_stn)\n",
    "            else:\n",
    "                # Shakespeare vdots\n",
    "                sk_vdots = Tex(r\"\\vdots\").next_to(sk_stns[-1], DOWN).shift(0.25*DOWN)\n",
    "                sk_stns.add(sk_vdots)\n",
    "                # Modern English vdots\n",
    "                md_vdots = Tex(r\"\\vdots\").next_to(md_stns[-1], DOWN).shift(0.25*DOWN)\n",
    "                md_stns.add(md_vdots)\n",
    "\n",
    "        sk_stns = sk_stns.scale(0.35).move_to(ORIGIN).to_edge(DOWN).shift(UP)\n",
    "        sk_stns_box = SurroundingRectangle(sk_stns, color=RED)\n",
    "        md_stns = md_stns.scale(0.35).move_to(ORIGIN).to_edge(DOWN).shift(UP)\n",
    "        md_stns_box = SurroundingRectangle(md_stns, color=BLUE)\n",
    "\n",
    "        self.play(Create(md_stns_box), Write(md_stns))\n",
    "        self.wait(1)\n",
    "\n",
    "        rendered_code = Code(file_name=\"../data/sk100_tokenizer.py\", tab_width=4, background=\"window\",\n",
    "                            language=\"Python\", font=\"Monospace\", insert_line_no=False,\n",
    "                            style=\"dracula\", line_spacing=1).scale(0.35).next_to(md_stns_box, UP)\n",
    "        rendered_code.code = remove_invisible_chars(rendered_code.code)\n",
    "        self.play(Create(rendered_code[0]), Write(rendered_code.code[0:2]), Write(rendered_code.code[2][:31]))\n",
    "        self.wait(1)\n",
    "        self.play(ReplacementTransform(VGroup(md_stns_box, md_stns), rendered_code.code[2][31:]))\n",
    "        self.wait(1)\n",
    "        self.play(Write(rendered_code.code[3][:11]))\n",
    "        self.wait(1)\n",
    "        self.play(Write(rendered_code.code[3][11:]), Write(rendered_code.code[4:]))\n",
    "        self.wait(1)\n",
    "        src = d[0,1]\n",
    "        src_stn = Tex(src).scale(0.5).next_to(rendered_code, DOWN).shift(0.25*DOWN)\n",
    "        modern = spm.SentencePieceProcessor(model_file=\"../trained_models/tokenizer/modern_en_vs100.model\")\n",
    "        src_tok = modern.EncodeAsPieces(src)\n",
    "        src_tok = [piece.lstrip('▁') for piece in src_tok]\n",
    "        src_tok = [piece for piece in src_tok if piece != '']\n",
    "\n",
    "        src_words = VGroup(Text(src_tok[0]))\n",
    "        src_words.add(SurroundingRectangle(src_words[-1], buff=0.25))\n",
    "        for word in src_tok[1:]:\n",
    "            src_words.add(Text(word).next_to(src_words[-1], RIGHT))\n",
    "            src_words.add(SurroundingRectangle(src_words[-1], buff=0.25))\n",
    "        src_words.scale(0.45).move_to(src_stn)\n",
    "        self.play(Write(src_stn))\n",
    "        self.wait(1)\n",
    "        self.play(ReplacementTransform(src_stn, src_words))\n",
    "        self.wait(1)\n",
    "        self.play(FadeOut(src_words))\n",
    "        self.wait(1)\n",
    "\n",
    "        rendered_code_ = Code(file_name=\"../data/sk5000_tokenizer.py\", tab_width=4, background=\"window\",\n",
    "                            language=\"Python\", font=\"Monospace\", insert_line_no=False,\n",
    "                            style=\"dracula\", line_spacing=1).scale(0.35).move_to(rendered_code)\n",
    "        rendered_code_.code = remove_invisible_chars(rendered_code_.code)\n",
    "        self.play(ReplacementTransform(rendered_code, rendered_code_))\n",
    "        self.wait(1)\n",
    "        src = d[0,1]\n",
    "        src_stn = Tex(src).scale(0.5).next_to(rendered_code_, DOWN).shift(0.25*DOWN)\n",
    "        modern = spm.SentencePieceProcessor(model_file=\"../trained_models/tokenizer/modern_en.model\")\n",
    "        src_tok = modern.EncodeAsPieces(src)\n",
    "        src_tok = [piece.lstrip('▁') for piece in src_tok]\n",
    "        src_tok = [piece for piece in src_tok if piece != '']\n",
    "\n",
    "        src_words = VGroup(Text(src_tok[0]))\n",
    "        src_words.add(SurroundingRectangle(src_words[-1], buff=0.25))\n",
    "        for word in src_tok[1:]:\n",
    "            src_words.add(Text(word).next_to(src_words[-1], RIGHT))\n",
    "            src_words.add(SurroundingRectangle(src_words[-1], buff=0.25))\n",
    "        src_words.scale(0.45).move_to(src_stn)\n",
    "        self.play(Write(src_stn))\n",
    "        self.wait(1)\n",
    "        self.play(ReplacementTransform(src_stn, src_words))\n",
    "        self.wait(1)\n",
    "        self.play(FadeOut(rendered_code_))\n",
    "        self.wait(1)\n",
    "\n",
    "        rendered_code = Code(file_name=\"../data/sk5000_tokenizer_call.py\", tab_width=4, background=\"window\",\n",
    "                            language=\"Python\", font=\"Monospace\", insert_line_no=False,\n",
    "                            style=\"dracula\", line_spacing=1).scale(0.35).move_to(rendered_code_)\n",
    "        rendered_code.code = remove_invisible_chars(rendered_code.code)\n",
    "        self.play(Write(rendered_code))\n",
    "        self.wait(1)\n",
    "        src_ids = modern.EncodeAsIds(src)\n",
    "        for i in range(0, len(src_ids)):\n",
    "            id = Tex(src_ids[i]).scale(0.5).move_to(src_words[i*2])\n",
    "            self.play(ReplacementTransform(src_words[i*2], id))\n",
    "        self.wait(1)\n",
    "\n",
    "        # Transition\n",
    "        self.play(\n",
    "            *[FadeOut(mob)for mob in self.mobjects]\n",
    "        )\n",
    "        self.wait(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding and Truncating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"media/jupyter/Padding@2024-04-27@17-26-42.mp4\" controls autoplay loop style=\"max-width: 60%;\"  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%manim -qk -v WARNING Padding\n",
    "\n",
    "class Padding(Scene):\n",
    "    def padding(self, tokenized_text, max_seq_len):\n",
    "        # Padding or trimming to fit the max sequence length\n",
    "        if len(tokenized_text) < max_seq_len:\n",
    "            left = max_seq_len - len(tokenized_text)\n",
    "            padding = [0] * left\n",
    "            tokenized_text += padding\n",
    "        else:\n",
    "            tokenized_text = tokenized_text[:max_seq_len]\n",
    "        return tokenized_text\n",
    "\n",
    "    def construct(self):\n",
    "        # Loading Dataset\n",
    "        df = pd.read_csv(\"../data/shk2mod.csv\", index_col=0)                           \n",
    "        df.drop(\"id\", axis=1, inplace=True)                                  \n",
    "        d = df.to_numpy()\n",
    "        src, trg = d[:,0], d[:,1]\n",
    "\n",
    "        # Showcasing dataset\n",
    "        sk_stns = VGroup(Tex(src[0]))\n",
    "        md_stns = VGroup(Tex(trg[0]))\n",
    "        np.random.seed(0)\n",
    "        idx = np.random.randint(1, len(src), 7)\n",
    "        for i in range(7):\n",
    "            if i != 3:\n",
    "                # Shakespeare sentence\n",
    "                sk_stn = Tex(src[idx[i]]).next_to(sk_stns[-1], DOWN).shift(0.25*DOWN)\n",
    "                sk_stns.add(sk_stn)\n",
    "                # Modern sentence\n",
    "                md_stn = Tex(trg[idx[i]]).next_to(md_stns[-1], DOWN).shift(0.25*DOWN)\n",
    "                md_stns.add(md_stn)\n",
    "            else:\n",
    "                # Shakespeare vdots\n",
    "                sk_vdots = Tex(r\"\\vdots\").next_to(sk_stns[-1], DOWN).shift(0.25*DOWN)\n",
    "                sk_stns.add(sk_vdots)\n",
    "                # Modern English vdots\n",
    "                md_vdots = Tex(r\"\\vdots\").next_to(md_stns[-1], DOWN).shift(0.25*DOWN)\n",
    "                md_stns.add(md_vdots)\n",
    "\n",
    "        sk_stns = sk_stns.scale(0.35).to_edge(UP).shift(DOWN).to_edge(LEFT)\n",
    "        sk_stns_box = SurroundingRectangle(sk_stns, color=RED)\n",
    "        md_stns = md_stns.scale(0.35).to_edge(UP).shift(DOWN).to_edge(RIGHT)\n",
    "        md_stns_box = SurroundingRectangle(md_stns, color=BLUE)\n",
    "\n",
    "        self.play(Create(sk_stns_box), Write(sk_stns))\n",
    "        self.wait(1)\n",
    "\n",
    "        self.play(Create(md_stns_box), Write(md_stns))\n",
    "        self.wait(1)\n",
    "\n",
    "        # Tokenize Dataset\n",
    "        shakespeare = spm.SentencePieceProcessor(model_file=\"../trained_models/tokenizer/shakespeare_en.model\")\n",
    "        src_tok = shakespeare.EncodeAsIds(list(src))\n",
    "        modern = spm.SentencePieceProcessor(model_file=\"../trained_models/tokenizer/modern_en.model\")\n",
    "        trg_tok = modern.EncodeAsIds(list(trg))\n",
    "        \n",
    "        sk_toks = VGroup(Tex(' '.join(map(str, src_tok[0]))))\n",
    "        md_toks = VGroup(Tex(' '.join(map(str, trg_tok[0]))))\n",
    "\n",
    "        np.random.seed(0)\n",
    "        idx = np.random.randint(1, len(src_tok), 7)\n",
    "        for i in range(7):\n",
    "            if i != 3:\n",
    "                # Shakespeare sentence\n",
    "                sk_stn = Tex(' '.join(map(str, src_tok[idx[i]]))).next_to(sk_toks[-1], DOWN).shift(0.25*DOWN)\n",
    "                sk_toks.add(sk_stn)\n",
    "                # Modern sentence\n",
    "                md_stn = Tex(' '.join(map(str, trg_tok[idx[i]]))).next_to(md_toks[-1], DOWN).shift(0.25*DOWN)\n",
    "                md_toks.add(md_stn)\n",
    "            else:\n",
    "                # Shakespeare vdots\n",
    "                sk_vdots = Tex(r\"\\vdots\").next_to(sk_toks[-1], DOWN).shift(0.25*DOWN)\n",
    "                sk_toks.add(sk_vdots)\n",
    "                # Modern English vdots\n",
    "                md_vdots = Tex(r\"\\vdots\").next_to(md_toks[-1], DOWN).shift(0.25*DOWN)\n",
    "                md_toks.add(md_vdots)\n",
    "\n",
    "        sk_toks = sk_toks.scale(0.35).to_edge(UP).shift(DOWN).to_edge(LEFT)\n",
    "        sk_toks_box = SurroundingRectangle(sk_toks, color=RED)\n",
    "        md_toks = md_toks.scale(0.35).to_edge(UP).shift(DOWN).to_edge(RIGHT)\n",
    "        md_toks_box = SurroundingRectangle(md_toks, color=BLUE)\n",
    "\n",
    "        self.play(ReplacementTransform(VGroup(sk_stns_box, sk_stns), VGroup(sk_toks_box, sk_toks)))\n",
    "        self.wait(1)\n",
    "\n",
    "        self.play(ReplacementTransform(VGroup(md_stns_box, md_stns), VGroup(md_toks_box, md_toks)))\n",
    "        self.wait(1)\n",
    "\n",
    "        # Padding Dataset\n",
    "        sk_toks_ = VGroup(Tex(' '.join(map(str, self.padding(src_tok[0], 20)))))\n",
    "        md_toks_ = VGroup(Tex(' '.join(map(str, self.padding(trg_tok[0], 20)))))\n",
    "\n",
    "        np.random.seed(0)\n",
    "        idx = np.random.randint(1, len(src_tok), 7)\n",
    "        for i in range(7):\n",
    "            if i != 3:\n",
    "                # Shakespeare sentence\n",
    "                sk_stn = Tex(' '.join(map(str, self.padding(src_tok[idx[i]], 20)))).next_to(sk_toks_[-1], DOWN).shift(0.25*DOWN)\n",
    "                sk_toks_.add(sk_stn)\n",
    "                # Modern sentence\n",
    "                md_stn = Tex(' '.join(map(str, self.padding(trg_tok[idx[i]], 20)))).next_to(md_toks_[-1], DOWN).shift(0.25*DOWN)\n",
    "                md_toks_.add(md_stn)\n",
    "            else:\n",
    "                # Shakespeare vdots\n",
    "                sk_vdots = Tex(r\"\\vdots\").next_to(sk_toks_[-1], DOWN).shift(0.25*DOWN)\n",
    "                sk_toks_.add(sk_vdots)\n",
    "                # Modern English vdots\n",
    "                md_vdots = Tex(r\"\\vdots\").next_to(md_toks_[-1], DOWN).shift(0.25*DOWN)\n",
    "                md_toks_.add(md_vdots)\n",
    "\n",
    "        sk_toks_ = sk_toks_.scale(0.35).to_edge(UP).shift(DOWN).to_edge(LEFT)\n",
    "        sk_toks_box_ = SurroundingRectangle(sk_toks_, color=RED)\n",
    "        md_toks_ = md_toks_.scale(0.35).to_edge(UP).shift(DOWN).to_edge(RIGHT)\n",
    "        md_toks_box_ = SurroundingRectangle(md_toks_, color=BLUE)\n",
    "\n",
    "        self.play(ReplacementTransform(VGroup(sk_toks_box, sk_toks), VGroup(sk_toks_box_, sk_toks_)))\n",
    "        self.wait(1)\n",
    "\n",
    "        self.play(ReplacementTransform(VGroup(md_toks_box, md_toks), VGroup(md_toks_box_, md_toks_)))\n",
    "        self.wait(1)\n",
    "\n",
    "        # Transition\n",
    "        self.play(\n",
    "            *[FadeOut(mob)for mob in self.mobjects]\n",
    "        )\n",
    "        self.wait(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                        \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"media/jupyter/SpecialTokens@2024-04-27@17-29-08.mp4\" controls autoplay loop style=\"max-width: 60%;\"  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%manim -qk -v WARNING SpecialTokens\n",
    "\n",
    "class SpecialTokens(Scene):\n",
    "    def construct(self):\n",
    "        # Encoder\n",
    "        encoder_text = Tex(\"Encoder\").scale(1).shift(3.75*LEFT+1.5*DOWN)\n",
    "        encoder_box = SurroundingRectangle(encoder_text, color=ORANGE, buff=MED_SMALL_BUFF, fill_opacity=0.15)\n",
    "        self.play(Create(encoder_box), Write(encoder_text))\n",
    "        self.wait(1)\n",
    "        input_text = Tex(\"You do not meet a man but frowns:\", \" [PAD]\", \" [PAD] [PAD] [PAD]\").scale(0.45).next_to(encoder_box, DOWN).shift(0.5*DOWN)\n",
    "        self.play(Write(input_text))\n",
    "        self.wait(1)\n",
    "        eos_tok = Tex(\" [EOS]\").scale(0.45).move_to(input_text[1])\n",
    "        self.play(ReplacementTransform(input_text[1], eos_tok))\n",
    "        self.wait(1)\n",
    "        intxt2enc = Line(input_text.get_edge_center(UP)+0.05*UP, encoder_box.get_edge_center(DOWN)+0.05*DOWN, color=WHITE)\n",
    "        self.play(Create(intxt2enc))\n",
    "        self.wait(1)\n",
    "        encoded_text = Tex(\"You\", \" do\", \" not\" , \" meet\", \" a\", \" man\", \" but\", \" frowns:\", \" [EOS]\", \" [PAD]\", \" [PAD]\", \" [PAD]\").scale(0.45).next_to(encoder_box, UP).shift(0.5*UP)\n",
    "        encoded_text.set_color_by_tex('You', RED_A)\n",
    "        encoded_text.set_color_by_tex('meet', RED_A)\n",
    "        encoded_text.set_color_by_tex('man', GREEN_A)\n",
    "        encoded_text.set_color_by_tex('frowns:', GREEN_A)\n",
    "        enc2outtxt = Line(encoder_box.get_edge_center(UP)+0.05*UP, encoded_text.get_edge_center(DOWN)+0.05*DOWN, color=WHITE)\n",
    "        self.play(Create(enc2outtxt))\n",
    "        self.wait(1)\n",
    "        self.play(Write(encoded_text))\n",
    "        self.wait(1)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_text = Tex(\"Decoder\").scale(1).next_to(encoded_text, RIGHT).shift(2*RIGHT)\n",
    "        decoder_box = SurroundingRectangle(decoder_text, color=BLUE_B, buff=MED_SMALL_BUFF, fill_opacity=0.15)\n",
    "        self.play(Create(decoder_box), Write(decoder_text))\n",
    "        self.wait(1)\n",
    "\n",
    "        outtxt2dec = Line(encoded_text.get_edge_center(RIGHT)+0.05*RIGHT, decoder_box.get_edge_center(LEFT)+0.05*LEFT, color=BLUE_A)\n",
    "        self.play(Create(outtxt2dec))\n",
    "\n",
    "        decoder_input = Tex(\"[BOS]\", \" Every\", \" man\", \" you\", \" meet\", \" these\", \" days\", \" is\", \" frowning\", \" [PAD]\", \" [PAD]\", \" [PAD]\").scale(0.45).next_to(decoder_box, DOWN).shift(0.5*DOWN)\n",
    "        decoder_input_box = SurroundingRectangle(decoder_input, color=WHITE, buff=MED_SMALL_BUFF)\n",
    "        decoder_in_text_connect = Line(decoder_input_box.get_edge_center(UP)+0.05*UP, decoder_box.get_edge_center(DOWN)+0.05*DOWN, color=WHITE)\n",
    "        decoder_output = Tex(\" Every\", \" man\", \" you\", \" meet\", \" these\", \" days\", \" is\", \" frowning\", \" [EOS]\", \" [PAD]\", \" [PAD]\", \" [PAD]\").scale(0.45).next_to(decoder_box, UP).shift(0.5*UP)\n",
    "        decoder_output_box = SurroundingRectangle(decoder_output, color=WHITE, buff=MED_SMALL_BUFF)\n",
    "        decoder_out_text_connect = Line(decoder_box.get_edge_center(UP)+0.05*UP, decoder_output_box.get_edge_center(DOWN)+0.05*DOWN, color=WHITE)\n",
    "        self.play(Create(decoder_input_box), Create(decoder_output_box), Create(decoder_in_text_connect), Create(decoder_out_text_connect))\n",
    "        self.wait(1)\n",
    "        for i in range(9):\n",
    "            self.play(Write(decoder_input[i]), run_time=0.5)\n",
    "            if i > 0:\n",
    "                self.play(FadeOut(connection), run_time=0.5)\n",
    "            self.play(Write(decoder_output[i]), run_time=0.5)\n",
    "            if i < 8:\n",
    "                connection = CurvedArrow(decoder_output_box.get_edge_center(RIGHT)+0.05*RIGHT, decoder_input_box.get_edge_center(RIGHT)+0.05*RIGHT, angle=-1.5707963267948966)\n",
    "                self.play(Create(connection), run_time=0.5)\n",
    "        self.wait(1)\n",
    "\n",
    "        self.play(Write(decoder_input[9:]), Write(decoder_output[9:]))\n",
    "        self.wait(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"media/jupyter/SpecialTokens_coded@2024-04-27@17-31-04.mp4\" controls autoplay loop style=\"max-width: 60%;\"  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%manim -qk -v WARNING SpecialTokens_coded\n",
    "\n",
    "class SpecialTokens_coded(Scene):\n",
    "    def construct(self):\n",
    "        # Transition\n",
    "        encoder_text = Tex(\"Encoder\").scale(1).shift(3.75*LEFT+1.5*DOWN)\n",
    "        encoder_box = SurroundingRectangle(encoder_text, color=ORANGE, buff=MED_SMALL_BUFF, fill_opacity=0.15)\n",
    "        input_text = Tex(\"You do not meet a man but frowns:\", \" [EOS]\", \" [PAD] [PAD] [PAD]\").scale(0.45).next_to(encoder_box, DOWN).shift(0.5*DOWN)\n",
    "        intxt2enc = Line(input_text.get_edge_center(UP)+0.05*UP, encoder_box.get_edge_center(DOWN)+0.05*DOWN, color=WHITE)\n",
    "        encoded_text = Tex(\"You\", \" do\", \" not\" , \" meet\", \" a\", \" man\", \" but\", \" frowns:\", \" [EOS]\", \" [PAD]\", \" [PAD]\", \" [PAD]\").scale(0.45).next_to(encoder_box, UP).shift(0.5*UP)\n",
    "        encoded_text.set_color_by_tex('You', RED_A)\n",
    "        encoded_text.set_color_by_tex('meet', RED_A)\n",
    "        encoded_text.set_color_by_tex('man', GREEN_A)\n",
    "        encoded_text.set_color_by_tex('frowns:', GREEN_A)\n",
    "        enc2outtxt = Line(encoder_box.get_edge_center(UP)+0.05*UP, encoded_text.get_edge_center(DOWN)+0.05*DOWN, color=WHITE)\n",
    "\n",
    "        decoder_text = Tex(\"Decoder\").scale(1).next_to(encoded_text, RIGHT).shift(2*RIGHT)\n",
    "        decoder_box = SurroundingRectangle(decoder_text, color=BLUE_B, buff=MED_SMALL_BUFF, fill_opacity=0.15)\n",
    "        outtxt2dec = Line(encoded_text.get_edge_center(RIGHT)+0.05*RIGHT, decoder_box.get_edge_center(LEFT)+0.05*LEFT, color=BLUE_A)\n",
    "\n",
    "        decoder_input = Tex(\"[BOS]\", \" Every\", \" man\", \" you\", \" meet\", \" these\", \" days\", \" is\", \" frowning\", \" [PAD]\", \" [PAD]\", \" [PAD]\").scale(0.45).next_to(decoder_box, DOWN).shift(0.5*DOWN)\n",
    "        decoder_input_box = SurroundingRectangle(decoder_input, color=WHITE, buff=MED_SMALL_BUFF)\n",
    "        decoder_in_text_connect = Line(decoder_input_box.get_edge_center(UP)+0.05*UP, decoder_box.get_edge_center(DOWN)+0.05*DOWN, color=WHITE)\n",
    "        decoder_output = Tex(\" Every\", \" man\", \" you\", \" meet\", \" these\", \" days\", \" is\", \" frowning\", \" [EOS]\", \" [PAD]\", \" [PAD]\", \" [PAD]\").scale(0.45).next_to(decoder_box, UP).shift(0.5*UP)\n",
    "        decoder_output_box = SurroundingRectangle(decoder_output, color=WHITE, buff=MED_SMALL_BUFF)\n",
    "        decoder_out_text_connect = Line(decoder_box.get_edge_center(UP)+0.05*UP, decoder_output_box.get_edge_center(DOWN)+0.05*DOWN, color=WHITE)\n",
    "        self.add(encoder_text, encoder_box, input_text, intxt2enc, \n",
    "                encoded_text, enc2outtxt, decoder_text, decoder_box,\n",
    "                outtxt2dec, decoder_input, decoder_input_box,\n",
    "                decoder_output, decoder_output_box, decoder_out_text_connect)\n",
    "        self.wait(1)\n",
    "\n",
    "        # SRC Processing\n",
    "        rendered_code = Code(file_name=\"../data/src_processing.py\", tab_width=4, background=\"window\",\n",
    "                            language=\"Python\", font=\"Monospace\", insert_line_no=False,\n",
    "                            style=\"dracula\", line_spacing=1).scale(0.43).next_to(encoded_text, UP).to_edge(LEFT)\n",
    "        rendered_code.code = remove_invisible_chars(rendered_code.code)\n",
    "        self.play(Create(rendered_code[0]), Create(rendered_code.code[0:2]))\n",
    "        self.wait(1)\n",
    "        self.play(Write(rendered_code.code[2:6]), Write(rendered_code.code[9:13]))\n",
    "        self.wait(1)\n",
    "        self.play(Write(rendered_code.code[6:9]), Write(rendered_code.code[13:]))\n",
    "        self.wait(1)\n",
    "        self.play(FadeOut(rendered_code))\n",
    "        self.wait(1)\n",
    "\n",
    "        # TRG IN Processing\n",
    "        rendered_code = Code(file_name=\"../data/trgin_processing.py\", tab_width=4, background=\"window\",\n",
    "                            language=\"Python\", font=\"Monospace\", insert_line_no=False,\n",
    "                            style=\"dracula\", line_spacing=1).scale(0.43).next_to(encoded_text, UP).to_edge(LEFT)\n",
    "        rendered_code.code = remove_invisible_chars(rendered_code.code)\n",
    "        self.play(Create(rendered_code[0]), Create(rendered_code.code[0:2]))\n",
    "        self.wait(1)\n",
    "        self.play(Write(rendered_code.code[2:4]))\n",
    "        self.wait(1)\n",
    "        self.play(Write(rendered_code.code[4:]))\n",
    "        self.wait(1)\n",
    "        self.play(FadeOut(rendered_code))\n",
    "        self.wait(1)\n",
    "\n",
    "        # TRG OUT Processing\n",
    "        rendered_code = Code(file_name=\"../data/trgout_processing.py\", tab_width=4, background=\"window\",\n",
    "                            language=\"Python\", font=\"Monospace\", insert_line_no=False,\n",
    "                            style=\"dracula\", line_spacing=1).scale(0.43).next_to(encoded_text, UP).to_edge(LEFT)\n",
    "        rendered_code.code = remove_invisible_chars(rendered_code.code)\n",
    "        self.play(Create(rendered_code[0]), Create(rendered_code.code[0:2]))\n",
    "        self.wait(1)\n",
    "        self.play(Write(rendered_code.code[2:6]), Write(rendered_code.code[9:13]))\n",
    "        self.wait(1)\n",
    "        self.play(Write(rendered_code.code[6:9]), Write(rendered_code.code[13:]))\n",
    "        self.wait(1)\n",
    "        self.wait(1)\n",
    "\n",
    "        # Transition\n",
    "        self.play(\n",
    "            *[FadeOut(mob)for mob in self.mobjects]\n",
    "        )\n",
    "        self.wait(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".anims",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
